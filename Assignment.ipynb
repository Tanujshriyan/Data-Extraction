{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import os, os.path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_data_df =  pd.read_excel('Input.xlsx')\n",
    "excel_data_df.head()\n",
    "links = excel_data_df['URL']\n",
    "URlID = excel_data_df['URL_ID']\n",
    "print(f'Total {len(links)} reports found')\n",
    "print(f'Total {len(URlID)} reports found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "i = 0\n",
    "for url in links:\n",
    "        r = requests.get(url, headers=headers)\n",
    "        data = r.text\n",
    "        soup = BeautifulSoup(data, 'html.parser')\n",
    "        #print(soup)\n",
    "        for each in ['h1']:\n",
    "            s = soup.find(each)\n",
    "            #print(p)\n",
    "            f = open(f'Textfiles/{URlID[i]}.txt', 'w+', encoding='utf-8')\n",
    "            f.write(''+s.extract().text)\n",
    "            f.close() \n",
    "        for data in soup.find_all(\"p\"):\n",
    "            f = open(f'Textfiles/{URlID[i]}.txt', 'a', encoding='utf-8')\n",
    "            f.write('\\n'+ data.get_text())\n",
    "            f.close() \n",
    "        i=i+1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('StopWords/StopWords_Generic.txt','r') as f:\n",
    "    stop_words_generic = f.read()\n",
    "\n",
    "stop_words_generic = stop_words_generic.split('\\n')\n",
    "print(f'Total number of Stop Words are {len(stop_words_generic)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MasterDictionary/positive-words.txt','r') as f:\n",
    "    positive_words = f.read()\n",
    "\n",
    "positive_words = positive_words.split('\\n')\n",
    "print(f'Total number of Positive Words are {len(positive_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MasterDictionary/negative-words.txt','r') as f:\n",
    "    negative_words = f.read()\n",
    "\n",
    "negative_words = negative_words.split('\\n')\n",
    "print(f'Total number of Negative Words are {len(negative_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = re.sub(r'[^A-Za-z]','',text.upper())\n",
    "    tokenized_words = word_tokenize(text)\n",
    "    return tokenized_words\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(r'[^A-Za-z]',' ',text.upper())\n",
    "    tokenized_words = word_tokenize(text)\n",
    "    return tokenized_words\n",
    "\n",
    "def remove_stopwords(words, stop_words):\n",
    "    return [x for x in words if x not in stop_words]\n",
    "    \n",
    "def countfunc(positive, negative, words):\n",
    "    score = 0\n",
    "    \n",
    "    paragraph = \" \".join(words)\n",
    "    count = Counter(paragraph.split())\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for key, val in count.items():\n",
    "        key = key.rstrip('.,?!\\n') # removing possible punctuation signs\n",
    "        if key in positive:\n",
    "            pos += val\n",
    "        if key in negative:\n",
    "            neg += val\n",
    "\n",
    "    return pos, neg\n",
    "\n",
    "def sentiment(score):\n",
    "    if(score < -0.5):\n",
    "        return 'Most Negative'\n",
    "    elif(score >= -0.5 and score < 0):\n",
    "        return 'Negative'\n",
    "    elif(score == 0):\n",
    "        return 'Neutral'\n",
    "    elif(score > 0 and score < 0.5):\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Very Positive'\n",
    "    \n",
    "\n",
    "def polarity(positive_score, negative_score):\n",
    "    return (positive_score - negative_score)/((positive_score + negative_score)+ 0.000001)\n",
    "     \n",
    "\n",
    "def subjectivity(positive_score, negative_score, num_words):\n",
    "    return (positive_score+negative_score)/(num_words+ 0.000001)\n",
    "\n",
    "def count_syllables(word):\n",
    "    for i in range(len(word)):\n",
    "        return len(\n",
    "            re.findall('(?!e$)[aeiouy]+', word[i], re.I) +\n",
    "            re.findall('^[^aeiouy]*e$', word[i], re.I)\n",
    "    )\n",
    "    \n",
    "def find_personal_pronouns(word):\n",
    "    text = ' '.join(word)\n",
    "\n",
    "    for i in range(len(text)):\n",
    "        pronounRegex = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
    "        pronouns = pronounRegex.findall(text)\n",
    "        return len(pronouns)\n",
    "\n",
    "def syllable_morethan2(word):\n",
    "    if(len(word) > 2 and (word[-2:] == 'es' or word[-2:] == 'ed')):\n",
    "        return False\n",
    "    \n",
    "    count =0\n",
    "    vowels = ['a','e','i','o','u']\n",
    "    for i in word:\n",
    "        if(i.lower() in vowels):\n",
    "            count = count +1\n",
    "        \n",
    "    if(count > 2):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def fog_index_cal(average_sentence_length, percentage_complexwords):\n",
    "    return 0.4*(average_sentence_length + percentage_complexwords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ['positive_score',\n",
    "      'negative_score',\n",
    "      'polarity_score',\n",
    "      'subjectivity_score',\n",
    "      'average_sentence_length',\n",
    "      'percentage_of_complex_words',\n",
    "      'fog_index',\n",
    "      'avg_number_of_words_per_sentence',\n",
    "      'complex_word_count',\n",
    "      'word_count',\n",
    "      'syllable_count',\n",
    "      'personal_pronouns',\n",
    "      'avg_word_length']\n",
    "\n",
    "for v in var:\n",
    "    excel_data_df[v] = 0\n",
    "    \n",
    "excel_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 0\n",
    "total_sentence_length = 0\n",
    "for i in range(1,len(URlID)):\n",
    "    with open(f'Textfiles/{i}.txt', 'r', encoding='utf8') as f:\n",
    "        x = f.read()\n",
    "        \n",
    "        if x:\n",
    "            start, end = 0, len(x)\n",
    "            content = x[start:end] \n",
    "            if ('...' not in content) and ('. . .' not in content) and len(content) > 200:\n",
    "                tokenized_words = tokenize(content) \n",
    "                #print(f'Total tokenized words are {len(tokenized_words)}')\n",
    "                \n",
    "                words = remove_stopwords(tokenized_words, stop_words_generic)\n",
    "                num_words = len(words)\n",
    "                #print(f'Total words after removing stop words are {len(words)}')\n",
    "                \n",
    "                positive_score,negative_score = countfunc(positive_words, negative_words, words)\n",
    "                 \n",
    "                #print(f'Total positive score is {positive_score}')\n",
    "                #print(f'Total negative score is {negative_score}')\n",
    "                \n",
    "                polarity_score = polarity(positive_score, negative_score)\n",
    "                #print(polarity_score)\n",
    "                \n",
    "                subjectivity_score = subjectivity(positive_score, negative_score, num_words)\n",
    "                #print(subjectivity_score)\n",
    "                #print(sentiment(polarity_score))\n",
    "                \n",
    "                sentences = sent_tokenize(content)\n",
    "                num_sentences = len(sentences)\n",
    "                \n",
    "                total_words =   num_words + total_words\n",
    "                total_sentence_length = total_sentence_length + num_sentences\n",
    "                average_sentence_length = num_words/num_sentences   \n",
    "        \n",
    "                num_complexword = 0\n",
    "                \n",
    "                for word in words:\n",
    "                    if(syllable_morethan2(word)):\n",
    "                        num_complexword = num_complexword+1\n",
    "                        \n",
    "                #print(num_complexword)\n",
    "                percentage_complexwords = num_complexword/num_words\n",
    "                #print(percentage_complexwords)\n",
    "                fog_index = fog_index_cal(average_sentence_length, percentage_complexwords)\n",
    "                #print(fog_index)\n",
    "                \n",
    "                positive_word_proportion = positive_score/num_words\n",
    "                negative_word_proportion = negative_score/num_words\n",
    "                \n",
    "                sen = words\n",
    "                average_word_length = sum(len(sens) for sens in sen)/ len(sen)\n",
    "                \n",
    "                syllable_count = count_syllables(words)\n",
    "                \n",
    "                personal_pronouns = find_personal_pronouns(words)\n",
    "                \n",
    "                \n",
    "                excel_data_df.loc[i,'positive_score'] = positive_score\n",
    "                excel_data_df.loc[i,'negative_score'] = negative_score\n",
    "                excel_data_df.loc[i,'polarity_score'] = polarity_score\n",
    "                excel_data_df.loc[i,'subjectivity_score'] = subjectivity_score\n",
    "                excel_data_df.loc[i,'average_sentence_length'] = average_sentence_length\n",
    "                excel_data_df.loc[i,'percentage_of_complex_words'] = percentage_complexwords\n",
    "                excel_data_df.loc[i,'fog_index'] = fog_index\n",
    "                excel_data_df.loc[i,'avg_number_of_words_per_sentence'] = total_words/total_sentence_length\n",
    "                excel_data_df.loc[i,'complex_word_count'] = num_complexword\n",
    "                excel_data_df.loc[i,'word_count'] = num_words\n",
    "                excel_data_df.loc[i,'syllable_count'] = syllable_count\n",
    "                excel_data_df.loc[i,'personal_pronouns'] = personal_pronouns\n",
    "                excel_data_df.loc[i,'avg_word_length'] = average_word_length\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>percentage_of_complex_words</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>avg_number_of_words_per_sentence</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>personal_pronouns</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-telehealt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.640000</td>\n",
       "      <td>0.601093</td>\n",
       "      <td>6.096437</td>\n",
       "      <td>14.640000</td>\n",
       "      <td>220</td>\n",
       "      <td>366</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7.188525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telemedici...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.018868</td>\n",
       "      <td>0.539749</td>\n",
       "      <td>3.823447</td>\n",
       "      <td>10.820513</td>\n",
       "      <td>258</td>\n",
       "      <td>478</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.625523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.408602</td>\n",
       "      <td>0.575872</td>\n",
       "      <td>4.793790</td>\n",
       "      <td>11.140351</td>\n",
       "      <td>611</td>\n",
       "      <td>1061</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.212064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-people-di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.872093</td>\n",
       "      <td>0.579946</td>\n",
       "      <td>5.380816</td>\n",
       "      <td>11.719844</td>\n",
       "      <td>642</td>\n",
       "      <td>1107</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.084011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  positive_score  \\\n",
       "0       1  https://insights.blackcoffer.com/is-telehealth...               0   \n",
       "1       2  https://insights.blackcoffer.com/how-telehealt...               0   \n",
       "2       3  https://insights.blackcoffer.com/is-telemedici...               0   \n",
       "3       4  https://insights.blackcoffer.com/is-telehealth...               0   \n",
       "4       5  https://insights.blackcoffer.com/how-people-di...               0   \n",
       "\n",
       "   negative_score  polarity_score  subjectivity_score  \\\n",
       "0               0               0                   0   \n",
       "1               0               0                   0   \n",
       "2               0               0                   0   \n",
       "3               0               0                   0   \n",
       "4               0               0                   0   \n",
       "\n",
       "   average_sentence_length  percentage_of_complex_words  fog_index  \\\n",
       "0                 0.000000                     0.000000   0.000000   \n",
       "1                14.640000                     0.601093   6.096437   \n",
       "2                 9.018868                     0.539749   3.823447   \n",
       "3                11.408602                     0.575872   4.793790   \n",
       "4                12.872093                     0.579946   5.380816   \n",
       "\n",
       "   avg_number_of_words_per_sentence  complex_word_count  word_count  \\\n",
       "0                          0.000000                   0           0   \n",
       "1                         14.640000                 220         366   \n",
       "2                         10.820513                 258         478   \n",
       "3                         11.140351                 611        1061   \n",
       "4                         11.719844                 642        1107   \n",
       "\n",
       "   syllable_count  personal_pronouns  avg_word_length  \n",
       "0               0                  0         0.000000  \n",
       "1               3                  0         7.188525  \n",
       "2               3                  0         6.625523  \n",
       "3               5                  0         7.212064  \n",
       "4               2                  0         7.084011  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {}\n",
    "options['strings_to_formulas'] = False\n",
    "options['strings_to_urls'] = False\n",
    "new_path = r\"G:\\Projects\\Python\\Data-Extraction\\Output Data Structure.xlsx\"\n",
    "writer = pd.ExcelWriter(new_path, engine='xlsxwriter',options=options)\n",
    "excel_data_df.to_excel(writer)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "095ec958f3b6558f9c0bdad00efbebd4de25b75269617557fb0d80a5cd9e4818"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
